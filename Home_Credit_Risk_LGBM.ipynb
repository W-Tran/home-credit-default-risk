{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_df = pd.read_csv(\"data/application_train.csv\")\n",
    "app_test_df = pd.read_csv(\"data/application_test.csv\")\n",
    "column_description_df = pd.read_csv(\"data/HomeCredit_columns_description.csv\", encoding='ISO-8859-1')\n",
    "train_labels = app_train_df.iloc[:,:2]\n",
    "test_id = app_test_df.iloc[:,0]\n",
    "\n",
    "bureau = pd.read_csv(\"data/bureau.csv\")\n",
    "bureau_balance = pd.read_csv(\"data/bureau_balance.csv\")\n",
    "\n",
    "def column_description_lookup(column):\n",
    "    print(column_description_df[column_description_df['Row']==column].Description.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domain only csv**\n",
    "\n",
    "`app_train_domain` will contain domain knowledge engineered features without polynomial features. These features were inspired by the awesome Kaggle competition notebooks that are available on the Kaggle competition website [such as this one](https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_domain = app_train_df.copy()\n",
    "app_test_domain = app_test_df.copy()\n",
    "\n",
    "app_train_domain['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']\n",
    "app_train_domain['PAYMENT_RATE'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
    "app_train_domain['INCOME_PER_PERSON'] = app_train_domain['AMT_INCOME_TOTAL'] / app_train_domain['CNT_FAM_MEMBERS']\n",
    "app_train_domain['INCOME_CREDIT_PERC'] = app_train_domain['AMT_INCOME_TOTAL'] / app_train_domain['AMT_CREDIT']\n",
    "\n",
    "app_test_domain['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']\n",
    "app_test_domain['PAYMENT_RATE'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
    "app_test_domain['INCOME_PER_PERSON'] = app_test_domain['AMT_INCOME_TOTAL'] / app_test_domain['CNT_FAM_MEMBERS']\n",
    "app_test_domain['INCOME_CREDIT_PERC'] = app_test_domain['AMT_INCOME_TOTAL'] / app_test_domain['AMT_CREDIT']\n",
    "\n",
    "\n",
    "app_train_domain.drop(columns=\"TARGET\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_domain.to_csv(\"app_train_domain.csv\", index=False)\n",
    "app_test_domain.to_csv(\"app_test_domain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine Poly with Domain and get csv** \n",
    "\n",
    "`app_train_poly` will contain the domain knowledge engineered features with the addition of interactions between the `EXT_SOURCE_X` and the `Days_Birth` features. They were created as these features have a relatively high correlation with the target compared to the other features. The idea to create these features was inspired by [this notebook](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features shape:  (307511, 35)\n"
     ]
    }
   ],
   "source": [
    "# Make a new dataframe for polynomial features\n",
    "poly_features = app_train_df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']].copy()\n",
    "poly_features['TARGET'] = train_labels['TARGET'].copy()\n",
    "poly_features_test = app_test_df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']].copy()\n",
    "\n",
    "# imputer for handling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "#poly_target = poly_features['TARGET']\n",
    "\n",
    "poly_features = poly_features.drop(columns = ['TARGET'])\n",
    "\n",
    "# Need to impute missing values\n",
    "poly_features = imputer.fit_transform(poly_features)\n",
    "poly_features_test = imputer.transform(poly_features_test)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "                                  \n",
    "# Create the polynomial object with specified degree\n",
    "poly_transformer = PolynomialFeatures(degree = 3)\n",
    "\n",
    "# Train the polynomial features\n",
    "poly_transformer.fit(poly_features)\n",
    "\n",
    "# Transform the features\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "print('Polynomial Features shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data with polynomial features shape:  (307511, 156)\n",
      "Testing data with polynomial features shape:   (48744, 156)\n"
     ]
    }
   ],
   "source": [
    "# Put train features into dataframe\n",
    "poly_features = pd.DataFrame(poly_features, \n",
    "                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                           'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Add in the target\n",
    "#poly_features['TARGET'] = poly_target\n",
    "\n",
    "# Put test features into dataframe\n",
    "poly_features_test = pd.DataFrame(poly_features_test, \n",
    "                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Merge polynomial features into training dataframe\n",
    "poly_features['SK_ID_CURR'] = app_train_df['SK_ID_CURR']\n",
    "app_train_poly = app_train_df.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge polnomial features into testing dataframe\n",
    "poly_features_test['SK_ID_CURR'] = app_test_df['SK_ID_CURR']\n",
    "app_test_poly = app_test_df.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Align the dataframes\n",
    "app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)\n",
    "\n",
    "# Print out the new shapes\n",
    "print('Training data with polynomial features shape: ', app_train_poly.shape)\n",
    "print('Testing data with polynomial features shape:  ', app_test_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 164)\n"
     ]
    }
   ],
   "source": [
    "for col in set(app_train_domain.columns) - set(app_train_poly.columns):\n",
    "    app_train_poly[col] = app_train_domain[col]\n",
    "    app_test_poly[col] = app_test_domain[col]\n",
    "print(app_train_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_poly.to_csv(\"app_train_poly_domain.csv\", index=False)\n",
    "app_test_poly.to_csv(\"app_test_poly_domain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in initial DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use domain AND polynomial features\n",
    "#app_train_df = pd.read_csv(\"app_train_poly_domain.csv\")\n",
    "#app_test_df = pd.read_csv(\"app_test_poly_domain.csv\")\n",
    "\n",
    "# Just use domain features\n",
    "app_train_df = pd.read_csv(\"app_train_domain.csv\")\n",
    "app_test_df = pd.read_csv(\"app_test_domain.csv\")\n",
    "\n",
    "app_train_df['SK_ID_CURR'] = app_train_df['SK_ID_CURR'].values.astype(int)\n",
    "app_test_df['SK_ID_CURR'] = app_test_df['SK_ID_CURR'].values.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incorporate Bureau and Bureau Balance features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df, group_var, df_name):\n",
    "    \"\"\"Aggregates the numeric values in a dataframe. This can\n",
    "    be used to create features for each instance of the grouping variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the dataframe to calculate the statistics on\n",
    "        group_var (string): \n",
    "            the variable by which to group df\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated for \n",
    "            all numeric columns. Each instance of the grouping variable will have \n",
    "            the statistics (mean, min, max, sum; currently supported) calculated. \n",
    "            The columns are also renamed to keep track of features created.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').copy()\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(group_var).agg(['mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        # Skip the grouping variable\n",
    "        if var != group_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categorical(df, group_var, df_name):\n",
    "    \"\"\"Computes counts and normalized counts for each observation\n",
    "    of `group_var` of each unique category in every categorical variable\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    group_var : string\n",
    "        The variable by which to group the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with counts and normalized counts of each unique category in every categorical variable\n",
    "        with one row for every unique value of the `group_var`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object')).copy()\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[group_var] = df[group_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    categorical.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
    "bureau_agg = bureau_agg.merge(bureau_counts, how='inner', on='SK_ID_CURR')\n",
    "del(bureau_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
    "bureau_balance_agg = bureau_balance_agg.merge(bureau_balance_counts, how='inner', on='SK_ID_BUREAU')\n",
    "del(bureau_balance_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_by_loan = bureau[['SK_ID_CURR', 'SK_ID_BUREAU']].merge(bureau_balance_agg, how='left', on='SK_ID_BUREAU')\n",
    "bureau_balance_by_applicant = agg_numeric(bureau_balance_by_loan, group_var='SK_ID_CURR', df_name = 'client')\n",
    "del(bureau_balance_by_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge with the value counts of bureau\n",
    "app_train_df = app_train_df.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test_df = app_test_df.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of bureau\n",
    "app_train_df = app_train_df.merge(bureau_balance_by_applicant, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test_df = app_test_df.merge(bureau_balance_by_applicant, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop low populated categorical feature classes and flag missing classes as \"MISSING\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = app_train_df.iloc[:,1:].copy()\n",
    "#test = app_test_df.iloc[:,1:].copy()\n",
    "\n",
    "train = app_train_df.copy()\n",
    "test = app_test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low populated categorical classes\n",
    "train_label = train_labels.copy()\n",
    "train_label.drop(train[train['CODE_GENDER'] == 'XNA'].index, inplace=True)\n",
    "train.drop(train[train['CODE_GENDER'] == 'XNA'].index, inplace=True)\n",
    "\n",
    "train_label.drop(train[train[\"NAME_INCOME_TYPE\"] == \"Maternity leave\"].index, inplace=True)\n",
    "train.drop(train[train[\"NAME_INCOME_TYPE\"] == \"Maternity leave\"].index, inplace=True)\n",
    "\n",
    "train_label.drop(train[train[\"NAME_FAMILY_STATUS\"] == \"Unknown\"].index, inplace=True)\n",
    "train.drop(train[train[\"NAME_FAMILY_STATUS\"] == \"Unknown\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of categorical variables\n",
    "binary_cat_feats = train.select_dtypes('object').nunique()[train.select_dtypes('object').nunique()==2].index\n",
    "cat_feats=train.select_dtypes('object').nunique()[train.select_dtypes('object').nunique()>2].index\n",
    "total_cat_feats = list(binary_cat_feats) + list(cat_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag missing classes\n",
    "for feat in total_cat_feats:\n",
    "    train[feat] = train[feat].fillna(\"MISSING\")\n",
    "    test[feat] = test[feat].fillna(\"MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detect categories in Training set that are not in Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cat_feat in total_cat_feats:\n",
    "    if len(set(train[cat_feat].value_counts().index)) != len(set(test[cat_feat].value_counts().index)):\n",
    "        print(cat_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label encode categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_classes = {}\n",
    "test_cat_classes = {}\n",
    "\n",
    "for cat_feat in total_cat_feats:\n",
    "    le = LabelEncoder()\n",
    "    train[cat_feat] = le.fit_transform(train[cat_feat])\n",
    "    train_cat_classes[cat_feat] = le.classes_\n",
    "    \n",
    "    test[cat_feat] = le.transform(test[cat_feat])\n",
    "    test_cat_classes[cat_feat] = le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace \"MISSING\" classes with negative number (treated as missing by LGBM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in train_cat_classes:\n",
    "    if \"MISSING\" in train_cat_classes[feat]:\n",
    "        train[feat] = train[feat].replace(list(train_cat_classes[feat]).index(\"MISSING\"), -1)\n",
    "        test[feat] = test[feat].replace(list(test_cat_classes[feat]).index(\"MISSING\"), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make categorical columns: \"category\" type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in total_cat_feats:\n",
    "    train[feat] = train[feat].astype('category')\n",
    "    test[feat] = test[feat].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"app_bureau_train.csv\", index=False)\n",
    "test.to_csv(\"app_bureau_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM with application and bureau features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform CV to find good number for n_estimators and check feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.770815\tvalid's binary_logloss: 0.543502\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid's auc: 0.771298\tvalid's binary_logloss: 0.537155\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.772807\tvalid's binary_logloss: 0.547614\n",
      "[400]\tvalid's auc: 0.773049\tvalid's binary_logloss: 0.523202\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid's auc: 0.773706\tvalid's binary_logloss: 0.532681\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.766202\tvalid's binary_logloss: 0.544239\n",
      "[400]\tvalid's auc: 0.766746\tvalid's binary_logloss: 0.519297\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid's auc: 0.767094\tvalid's binary_logloss: 0.5261\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.772531\tvalid's binary_logloss: 0.543583\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid's auc: 0.773032\tvalid's binary_logloss: 0.53157\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.774141\tvalid's binary_logloss: 0.543628\n",
      "[400]\tvalid's auc: 0.774531\tvalid's binary_logloss: 0.520042\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid's auc: 0.774787\tvalid's binary_logloss: 0.526091\n"
     ]
    }
   ],
   "source": [
    "label = train_label['TARGET'].copy()\n",
    "\n",
    "cv_n_estimators = []\n",
    "cv_scores = []\n",
    "fi = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, val_index in skf.split(X=train, y=label):\n",
    "    #X_train, y_train = train[train_index], label[train_index]\n",
    "    #X_val, y_val = train[val_index], label[val_index]\n",
    "    \n",
    "    # Split as DataFrame\n",
    "    X_train, y_train = train.iloc[train_index,:], label.iloc[train_index]\n",
    "    X_val, y_val = train.iloc[val_index,:], label.iloc[val_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = LGBMClassifier(n_estimators=10000, \n",
    "                           num_leaves=31,\n",
    "                           objective = 'binary', \n",
    "                           class_weight = 'balanced', \n",
    "                           learning_rate = 0.05, \n",
    "                           #reg_alpha = 0.1, \n",
    "                           #reg_lambda = 0.1, \n",
    "                           subsample = 0.8, \n",
    "                           colsample_by_tree=0.50,\n",
    "                           n_jobs = 4, \n",
    "                           random_state = 1)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              eval_metric = 'auc',\n",
    "              eval_set = [(X_val, y_val)],\n",
    "              eval_names = ['valid'], \n",
    "              categorical_feature = 'auto',\n",
    "              early_stopping_rounds = 100, \n",
    "              verbose = 200)\n",
    "    \n",
    "    cv_n_estimators.append(model.best_iteration_)\n",
    "    cv_scores.append(model.best_score_['valid']['auc'])\n",
    "    fi.append(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: [247, 314, 338, 289, 343]\n",
      "Best n_estimators (AVG): 306.2\n",
      "Best CV AUCs: [0.7712976330279125, 0.7737063220668352, 0.7670938525992196, 0.7730321443427791, 0.7747867034084339]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best n_estimators: {}\".format(cv_n_estimators))\n",
    "print(\"Best n_estimators (AVG): {}\".format(np.mean(cv_n_estimators)))\n",
    "print(\"Best CV AUCs: {}\".format(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>FI</th>\n",
       "      <th>FI_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ORGANIZATION_TYPE</td>\n",
       "      <td>6771</td>\n",
       "      <td>0.147420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>CREDIT_TERM</td>\n",
       "      <td>2801</td>\n",
       "      <td>0.060984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OCCUPATION_TYPE</td>\n",
       "      <td>992</td>\n",
       "      <td>0.021598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3</td>\n",
       "      <td>951</td>\n",
       "      <td>0.020705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>EXT_SOURCE_1_x</td>\n",
       "      <td>848</td>\n",
       "      <td>0.018463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>761</td>\n",
       "      <td>0.016569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMT_GOODS_PRICE</td>\n",
       "      <td>731</td>\n",
       "      <td>0.015916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DAYS_ID_PUBLISH</td>\n",
       "      <td>653</td>\n",
       "      <td>0.014217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>bureau_DAYS_CREDIT_ENDDATE_max</td>\n",
       "      <td>650</td>\n",
       "      <td>0.014152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMT_CREDIT</td>\n",
       "      <td>649</td>\n",
       "      <td>0.014130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>DAYS_EMPLOYED_PERCENT</td>\n",
       "      <td>598</td>\n",
       "      <td>0.013020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OWN_CAR_AGE</td>\n",
       "      <td>591</td>\n",
       "      <td>0.012867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>bureau_DAYS_CREDIT_max</td>\n",
       "      <td>579</td>\n",
       "      <td>0.012606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>EXT_SOURCE_3_x</td>\n",
       "      <td>547</td>\n",
       "      <td>0.011909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>bureau_AMT_CREDIT_SUM_DEBT_mean</td>\n",
       "      <td>528</td>\n",
       "      <td>0.011496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>bureau_DAYS_ENDDATE_FACT_max</td>\n",
       "      <td>505</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>ANNUITY_INCOME_PERCENT</td>\n",
       "      <td>472</td>\n",
       "      <td>0.010277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>DAYS_LAST_PHONE_CHANGE</td>\n",
       "      <td>449</td>\n",
       "      <td>0.009776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DAYS_REGISTRATION</td>\n",
       "      <td>442</td>\n",
       "      <td>0.009623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>EXT_SOURCE_2 EXT_SOURCE_3^2</td>\n",
       "      <td>394</td>\n",
       "      <td>0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "      <td>392</td>\n",
       "      <td>0.008535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH</td>\n",
       "      <td>378</td>\n",
       "      <td>0.008230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>bureau_AMT_CREDIT_SUM_mean</td>\n",
       "      <td>367</td>\n",
       "      <td>0.007990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DAYS_BIRTH_x</td>\n",
       "      <td>362</td>\n",
       "      <td>0.007882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>CREDIT_INCOME_PERCENT</td>\n",
       "      <td>358</td>\n",
       "      <td>0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>EXT_SOURCE_2^2 EXT_SOURCE_3</td>\n",
       "      <td>358</td>\n",
       "      <td>0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>355</td>\n",
       "      <td>0.007729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>REGION_POPULATION_RELATIVE</td>\n",
       "      <td>340</td>\n",
       "      <td>0.007403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>EXT_SOURCE_1 EXT_SOURCE_3 DAYS_BIRTH</td>\n",
       "      <td>337</td>\n",
       "      <td>0.007337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>bureau_AMT_CREDIT_SUM_min</td>\n",
       "      <td>336</td>\n",
       "      <td>0.007315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>EXT_SOURCE_1^2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FLAG_DOCUMENT_7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>FLAG_DOCUMENT_20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>client_bureau_balance_STATUS_1_count_norm_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>client_bureau_balance_STATUS_1_count_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>FLAG_DOCUMENT_9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>FLAG_DOCUMENT_10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>client_bureau_balance_STATUS_0_count_norm_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>FLAG_DOCUMENT_12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>client_bureau_balance_STATUS_0_count_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>client_bureau_balance_MONTHS_BALANCE_sum_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>FLAG_DOCUMENT_17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>client_bureau_balance_MONTHS_BALANCE_min_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>FLAG_DOCUMENT_19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>client_bureau_balance_MONTHS_BALANCE_max_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>FLAG_DOCUMENT_21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>DAYS_BIRTH_y</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>AMT_REQ_CREDIT_BUREAU_HOUR</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>bureau_CREDIT_TYPE_Real estate loan_count_norm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>bureau_CREDIT_TYPE_Real estate loan_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>bureau_CREDIT_TYPE_Mobile operator loan_count_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>bureau_CREDIT_TYPE_Mobile operator loan_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>bureau_CREDIT_TYPE_Loan for the purchase of eq...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>bureau_CREDIT_TYPE_Loan for the purchase of eq...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>bureau_CREDIT_TYPE_Loan for purchase of shares...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>bureau_CREDIT_TYPE_Loan for purchase of shares...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>bureau_CREDIT_TYPE_Interbank credit_count_norm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>bureau_CREDIT_TYPE_Interbank credit_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>bureau_CREDIT_ACTIVE_Bad debt_count_norm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature    FI  FI_normalized\n",
       "38                                   ORGANIZATION_TYPE  6771       0.147420\n",
       "156                                        CREDIT_TERM  2801       0.060984\n",
       "26                                     OCCUPATION_TYPE   992       0.021598\n",
       "140             EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3   951       0.020705\n",
       "39                                      EXT_SOURCE_1_x   848       0.018463\n",
       "..                                                 ...   ...            ...\n",
       "254  bureau_CREDIT_TYPE_Loan for purchase of shares...     0       0.000000\n",
       "253  bureau_CREDIT_TYPE_Loan for purchase of shares...     0       0.000000\n",
       "250     bureau_CREDIT_TYPE_Interbank credit_count_norm     0       0.000000\n",
       "249          bureau_CREDIT_TYPE_Interbank credit_count     0       0.000000\n",
       "226           bureau_CREDIT_ACTIVE_Bad debt_count_norm     0       0.000000\n",
       "\n",
       "[374 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_arr = np.zeros_like(fi[0])\n",
    "for fi_cv in fi:\n",
    "    fi_arr += fi_cv\n",
    "\n",
    "fi_df = {}\n",
    "for name, fi_feat in zip(list(train.columns), fi_arr):\n",
    "    fi_df[name] = fi_feat\n",
    "fi_df = pd.DataFrame(pd.Series(fi_df), columns=['FI'])\n",
    "fi_df['FI_normalized'] = fi_df['FI'] / fi_df['FI'].sum()\n",
    "fi_df.reset_index(level=0, inplace=True)\n",
    "fi_df.rename(columns={'index':'Feature'}, inplace=True)\n",
    "fi_df.sort_values(by='FI', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_df.to_csv(\"fi_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fi_1** - Poly features included. No OHE encoding. Pandas DF with categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_by_tree=0.5, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=300, n_jobs=4, num_leaves=31, objective='binary',\n",
       "               random_state=1, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(n_estimators=300, \n",
    "                           num_leaves=31,\n",
    "                           objective = 'binary', \n",
    "                           class_weight = 'balanced', \n",
    "                           learning_rate = 0.05, \n",
    "                           #reg_alpha = 0.1, \n",
    "                           #reg_lambda = 0.1, \n",
    "                           subsample = 0.8, \n",
    "                           colsample_by_tree=0.50,\n",
    "                           n_jobs = 4, \n",
    "                           random_state = 1)\n",
    "model.fit(train, \n",
    "          label, \n",
    "          eval_metric = 'auc',\n",
    "          categorical_feature = 'auto',\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test)[:,1]\n",
    "submission_df = pd.DataFrame(test_id)\n",
    "submission_df['TARGET'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"28082019_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **0.76906** - \"Domain\", poly and bureau aggregated features\n",
    "- **0.76910** - \"Domain\", poly and bureau aggregated features. Don't OHE categorical features\n",
    "- **0.76972** - Don't OHE categorical features, colsample_by_tree = 0.5, no reg\n",
    "- **0.76736** - Don't OHE categorical features, Don't include poly features, colsample_by_tree = 0.5, no reg\n",
    "- **0.76972** - Don't OHE categorical features, colsample_by_tree = 0.5, no reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop low feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi_df = pd.read_csv(\"fi_1.csv\")\n",
    "low_fi_feats = list(fi_df[fi_df['FI']==0].Feature.values)\n",
    "\n",
    "train_drop_low_fi = train.copy()\n",
    "test_drop_low_fi = test.copy()\n",
    "\n",
    "train_drop_low_fi.drop(columns=low_fi_feats, inplace=True)\n",
    "test_drop_low_fi.drop(columns=low_fi_feats, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.770815\tvalid's binary_logloss: 0.543502\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid's auc: 0.771298\tvalid's binary_logloss: 0.537155\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.772807\tvalid's binary_logloss: 0.547614\n",
      "[400]\tvalid's auc: 0.773049\tvalid's binary_logloss: 0.523202\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid's auc: 0.773706\tvalid's binary_logloss: 0.532681\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.766202\tvalid's binary_logloss: 0.544239\n",
      "[400]\tvalid's auc: 0.766746\tvalid's binary_logloss: 0.519297\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid's auc: 0.767094\tvalid's binary_logloss: 0.5261\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.772531\tvalid's binary_logloss: 0.543583\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid's auc: 0.773032\tvalid's binary_logloss: 0.53157\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.774141\tvalid's binary_logloss: 0.543628\n",
      "[400]\tvalid's auc: 0.774531\tvalid's binary_logloss: 0.520042\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid's auc: 0.774787\tvalid's binary_logloss: 0.526091\n"
     ]
    }
   ],
   "source": [
    "label = train_label['TARGET'].copy()\n",
    "\n",
    "cv_n_estimators = []\n",
    "cv_scores = []\n",
    "fi = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, val_index in skf.split(X=train_drop_low_fi, y=label):\n",
    "    #X_train, y_train = train[train_index], label[train_index]\n",
    "    #X_val, y_val = train[val_index], label[val_index]\n",
    "    \n",
    "    # Split as DataFrame\n",
    "    X_train, y_train = train_drop_low_fi.iloc[train_index,:], label.iloc[train_index]\n",
    "    X_val, y_val = train_drop_low_fi.iloc[val_index,:], label.iloc[val_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = LGBMClassifier(n_estimators=10000, \n",
    "                           num_leaves=31,\n",
    "                           objective = 'binary', \n",
    "                           class_weight = 'balanced', \n",
    "                           learning_rate = 0.05, \n",
    "                           #reg_alpha = 0.1, \n",
    "                           #reg_lambda = 0.1, \n",
    "                           subsample = 0.8, \n",
    "                           colsample_by_tree=0.50,\n",
    "                           n_jobs = 4, \n",
    "                           random_state = 2)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              eval_metric = 'auc',\n",
    "              eval_set = [(X_val, y_val)],\n",
    "              eval_names = ['valid'], \n",
    "              categorical_feature = 'auto',\n",
    "              early_stopping_rounds = 100, \n",
    "              verbose = 200)\n",
    "    \n",
    "    cv_n_estimators.append(model.best_iteration_)\n",
    "    cv_scores.append(model.best_score_['valid']['auc'])\n",
    "    fi.append(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: [247, 314, 338, 289, 343]\n",
      "Best n_estimators (AVG): 306.2\n",
      "Best CV AUCs: [0.7712976330279125, 0.7737063220668352, 0.7670938525992196, 0.7730321443427791, 0.7747867034084339]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best n_estimators: {}\".format(cv_n_estimators))\n",
    "print(\"Best n_estimators (AVG): {}\".format(np.mean(cv_n_estimators)))\n",
    "print(\"Best CV AUCs: {}\".format(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FI</th>\n",
       "      <th>FI_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <td>6771</td>\n",
       "      <td>0.147420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_TERM</th>\n",
       "      <td>2801</td>\n",
       "      <td>0.060984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <td>992</td>\n",
       "      <td>0.021598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3</th>\n",
       "      <td>951</td>\n",
       "      <td>0.020705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_1_x</th>\n",
       "      <td>848</td>\n",
       "      <td>0.018463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>761</td>\n",
       "      <td>0.016569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>731</td>\n",
       "      <td>0.015916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <td>653</td>\n",
       "      <td>0.014217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_DAYS_CREDIT_ENDDATE_max</th>\n",
       "      <td>650</td>\n",
       "      <td>0.014152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>649</td>\n",
       "      <td>0.014130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_EMPLOYED_PERCENT</th>\n",
       "      <td>598</td>\n",
       "      <td>0.013020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <td>591</td>\n",
       "      <td>0.012867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_DAYS_CREDIT_max</th>\n",
       "      <td>579</td>\n",
       "      <td>0.012606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_3_x</th>\n",
       "      <td>547</td>\n",
       "      <td>0.011909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_AMT_CREDIT_SUM_DEBT_mean</th>\n",
       "      <td>528</td>\n",
       "      <td>0.011496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_DAYS_ENDDATE_FACT_max</th>\n",
       "      <td>505</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANNUITY_INCOME_PERCENT</th>\n",
       "      <td>472</td>\n",
       "      <td>0.010277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <td>449</td>\n",
       "      <td>0.009776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <td>442</td>\n",
       "      <td>0.009623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_2 EXT_SOURCE_3^2</th>\n",
       "      <td>394</td>\n",
       "      <td>0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <td>392</td>\n",
       "      <td>0.008535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH</th>\n",
       "      <td>378</td>\n",
       "      <td>0.008230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_AMT_CREDIT_SUM_mean</th>\n",
       "      <td>367</td>\n",
       "      <td>0.007990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_BIRTH_x</th>\n",
       "      <td>362</td>\n",
       "      <td>0.007882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_INCOME_PERCENT</th>\n",
       "      <td>358</td>\n",
       "      <td>0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_2^2 EXT_SOURCE_3</th>\n",
       "      <td>358</td>\n",
       "      <td>0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <td>355</td>\n",
       "      <td>0.007729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <td>340</td>\n",
       "      <td>0.007403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_1 EXT_SOURCE_3 DAYS_BIRTH</th>\n",
       "      <td>337</td>\n",
       "      <td>0.007337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_AMT_CREDIT_SUM_min</th>\n",
       "      <td>336</td>\n",
       "      <td>0.007315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_5_count_max</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_DAY_OVERDUE_sum</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_5_count_min</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_TYPE_Loan for business development_count</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_3_count_norm_sum</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_4_count_mean</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_CURRENCY_currency 1_count_norm</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_5_count_norm_mean</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_CURRENCY_currency 3_count_norm</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_TYPE_Unknown type of loan_count_norm</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_4_count_norm_max</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_4_count_max</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_3_count_norm_max</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_3_count_norm_mean</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_TYPE_Loan for working capital replenishment_count_norm</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_2_count_norm_min</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_TYPE_Unknown type of loan_count</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_TYPE_Another type of loan_count</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_2_count_max</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_CURRENCY_currency 2_count_norm</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_TYPE_Loan for working capital replenishment_count</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_bureau_balance_STATUS_2_count_sum</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CNT_CREDIT_PROLONG_min</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CNT_CREDIT_PROLONG_sum</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_CREDIT_TYPE_Loan for business development_count_norm</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      FI  FI_normalized\n",
       "ORGANIZATION_TYPE                                   6771       0.147420\n",
       "CREDIT_TERM                                         2801       0.060984\n",
       "OCCUPATION_TYPE                                      992       0.021598\n",
       "EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3               951       0.020705\n",
       "EXT_SOURCE_1_x                                       848       0.018463\n",
       "...                                                  ...            ...\n",
       "client_bureau_balance_STATUS_2_count_sum               1       0.000022\n",
       "REG_REGION_NOT_LIVE_REGION                             1       0.000022\n",
       "bureau_CNT_CREDIT_PROLONG_min                          1       0.000022\n",
       "bureau_CNT_CREDIT_PROLONG_sum                          1       0.000022\n",
       "bureau_CREDIT_TYPE_Loan for business developmen...     1       0.000022\n",
       "\n",
       "[288 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_arr = np.zeros_like(fi[0])\n",
    "for fi_cv in fi:\n",
    "    fi_arr += fi_cv\n",
    "\n",
    "fi_df = {}\n",
    "for name, fi_feat in zip(list(train_drop_low_fi.columns), fi_arr):\n",
    "    fi_df[name] = fi_feat\n",
    "fi_df = pd.DataFrame(pd.Series(fi_df), columns=['FI'])\n",
    "fi_df['FI_normalized'] = fi_df['FI'] / fi_df['FI'].sum()\n",
    "fi_df.sort_values(by='FI', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_by_tree=0.5, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=325, n_jobs=4, num_leaves=31, objective='binary',\n",
       "               random_state=2, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = train_label['TARGET'].copy()\n",
    "model = LGBMClassifier(n_estimators=325, \n",
    "                           num_leaves=31,\n",
    "                           objective = 'binary', \n",
    "                           class_weight = 'balanced', \n",
    "                           learning_rate = 0.05, \n",
    "                           #reg_alpha = 0.1, \n",
    "                           #reg_lambda = 0.1, \n",
    "                           subsample = 0.8, \n",
    "                           colsample_by_tree=0.50,\n",
    "                           n_jobs = 4, \n",
    "                           random_state = 2)\n",
    "    \n",
    "model.fit(train_drop_low_fi, \n",
    "          label, \n",
    "          eval_metric = 'auc',\n",
    "          categorical_feature = 'auto',\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test_drop_low_fi)[:,1]\n",
    "submission_df = pd.DataFrame(test_id)\n",
    "submission_df['TARGET'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"28082019_8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **0.77098** - Don't OHE categorical features, colsample_by_tree = 0.5, no reg. Drop 0 feature importance features\n",
    "- **0.76967** - Don't OHE categorical features, colsample_by_tree = 0.5, no reg. Drop 0 feature importance features. Seed=2 (different `FI_1.csv` file)\n",
    "- **0.77098** - Don't OHE categorical features, colsample_by_tree = 0.5, no reg. Drop 0 feature importance features **Back to previous FI_1.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drop_low_fi.to_csv(\"app_bureau_train_poly.csv\", index=False)\n",
    "test_drop_low_fi.to_csv(\"app_bureau_test_poly.csv\", index=False)\n",
    "pd.DataFrame(label).to_csv(\"train_label_dropped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporate all other table's features\n",
    "\n",
    "Because of the one to many relationships between the unique identifiers within the tables, we will simply aggregate features using various aggregation statistics to combine the features into one table, just like how was done with bureau and bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test_df = pd.read_csv(\"data/application_test.csv\")\n",
    "column_description_df = pd.read_csv(\"data/HomeCredit_columns_description.csv\", encoding='ISO-8859-1')\n",
    "test_id = app_test_df.iloc[:,0]\n",
    "\n",
    "def column_description_lookup(column):\n",
    "    print(column_description_df[column_description_df['Row']==column].Description.values[0])\n",
    "\n",
    "app_train_df = pd.read_csv(\"app_bureau_train.csv\")\n",
    "app_test_df = pd.read_csv(\"app_bureau_test.csv\")\n",
    "train_label = pd.read_csv(\"train_label_dropped.csv\")\n",
    "\n",
    "\n",
    "total_cat_feats=['NAME_CONTRACT_TYPE',\n",
    " 'CODE_GENDER',\n",
    " 'FLAG_OWN_CAR',\n",
    " 'FLAG_OWN_REALTY',\n",
    " 'EMERGENCYSTATE_MODE',\n",
    " 'NAME_TYPE_SUITE',\n",
    " 'NAME_INCOME_TYPE',\n",
    " 'NAME_EDUCATION_TYPE',\n",
    " 'NAME_FAMILY_STATUS',\n",
    " 'NAME_HOUSING_TYPE',\n",
    " 'OCCUPATION_TYPE',\n",
    " 'WEEKDAY_APPR_PROCESS_START',\n",
    " 'ORGANIZATION_TYPE',\n",
    " 'FONDKAPREMONT_MODE',\n",
    " 'HOUSETYPE_MODE',\n",
    " 'WALLSMATERIAL_MODE']\n",
    "\n",
    "for feat in total_cat_feats:\n",
    "    app_train_df[feat] = app_train_df[feat].astype('category')\n",
    "    app_test_df[feat] = app_test_df[feat].astype('category')\n",
    "\n",
    "previous = pd.read_csv(\"data/previous_application.csv\")\n",
    "cash = pd.read_csv(\"data/POS_CASH_balance.csv\")\n",
    "credit = pd.read_csv('data/credit_card_balance.csv')\n",
    "installments = pd.read_csv('data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "previous['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "previous['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "previous['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "previous['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "previous['APP_CREDIT_PERC'] = previous['AMT_APPLICATION'] / previous['AMT_CREDIT']\n",
    "\n",
    "installments['PAYMENT_PERC'] = installments['AMT_PAYMENT'] / installments['AMT_INSTALMENT']\n",
    "installments['PAYMENT_DIFF'] = installments['AMT_INSTALMENT'] - installments['AMT_PAYMENT']\n",
    "installments['DPD'] = installments['DAYS_ENTRY_PAYMENT'] - installments['DAYS_INSTALMENT']\n",
    "installments['DBD'] = installments['DAYS_INSTALMENT'] - installments['DAYS_ENTRY_PAYMENT']\n",
    "installments['DPD'] = installments['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "installments['DBD'] = installments['DBD'].apply(lambda x: x if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df, group_var, df_name):\n",
    "    \"\"\"Aggregates the numeric values in a dataframe. This can\n",
    "    be used to create features for each instance of the grouping variable.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        df (dataframe): \n",
    "            the dataframe to calculate the statistics on\n",
    "        group_var (string): \n",
    "            the variable by which to group df\n",
    "        df_name (string): \n",
    "            the variable used to rename the columns\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        agg (dataframe): \n",
    "            a dataframe with the statistics aggregated for \n",
    "            all numeric columns. Each instance of the grouping variable will have \n",
    "            the statistics (mean, min, max, sum; currently supported) calculated. \n",
    "            The columns are also renamed to keep track of features created.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove id variables other than grouping variable\n",
    "    for col in df:\n",
    "        if col != group_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    group_ids = df[group_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').copy()\n",
    "    numeric_df[group_var] = group_ids\n",
    "\n",
    "    # Group by the specified variable and calculate the statistics\n",
    "    agg = numeric_df.groupby(group_var).agg(['mean', 'max', 'min', 'sum']).reset_index()\n",
    "\n",
    "    # Need to create new column names\n",
    "    columns = [group_var]\n",
    "\n",
    "    # Iterate through the variables names\n",
    "    for var in agg.columns.levels[0]:\n",
    "        # Skip the grouping variable\n",
    "        if var != group_var:\n",
    "            # Iterate through the stat names\n",
    "            for stat in agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "\n",
    "    agg.columns = columns\n",
    "    \n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categorical(df, group_var, df_name):\n",
    "    \"\"\"Computes counts and normalized counts for each observation\n",
    "    of `group_var` of each unique category in every categorical variable\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe \n",
    "        The dataframe to calculate the value counts for.\n",
    "        \n",
    "    group_var : string\n",
    "        The variable by which to group the dataframe. For each unique\n",
    "        value of this variable, the final dataframe will have one row\n",
    "        \n",
    "    df_name : string\n",
    "        Variable added to the front of column names to keep track of columns\n",
    "\n",
    "    \n",
    "    Return\n",
    "    --------\n",
    "    categorical : dataframe\n",
    "        A dataframe with counts and normalized counts of each unique category in every categorical variable\n",
    "        with one row for every unique value of the `group_var`.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the categorical columns\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object')).copy()\n",
    "\n",
    "    # Make sure to put the identifying id on the column\n",
    "    categorical[group_var] = df[group_var]\n",
    "\n",
    "    # Groupby the group var and calculate the sum and mean\n",
    "    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    \n",
    "    # Iterate through the columns in level 0\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        # Iterate through the stats in level 1\n",
    "        for stat in ['count', 'count_norm']:\n",
    "            # Make a new column name\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    \n",
    "    categorical.columns = column_names\n",
    "    categorical.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_counts = count_categorical(previous, group_var = 'SK_ID_CURR', df_name = 'previous')\n",
    "previous_agg = agg_numeric(previous.drop(columns = ['SK_ID_PREV']), group_var = 'SK_ID_CURR', df_name = 'previous')\n",
    "previous_agg = previous_agg.merge(previous_counts, how='inner', on='SK_ID_CURR')\n",
    "del(previous_counts)\n",
    "\n",
    "previous_agg_missing_df = pd.DataFrame(previous_agg.isna().sum(axis=0).sort_values(ascending=False)).rename(columns={0:\"Total\"})\n",
    "previous_agg_missing_df['%'] = np.round(previous_agg_missing_df.Total/len(previous_agg)*100, 2)\n",
    "to_drop = list(previous_agg_missing_df[previous_agg_missing_df['%']>90].index)\n",
    "previous_agg.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_counts = count_categorical(cash, group_var = 'SK_ID_PREV', df_name = 'cash')\n",
    "cash_agg = agg_numeric(cash, group_var = 'SK_ID_PREV', df_name = 'cash')\n",
    "cash_agg = cash_agg.merge(cash_counts, how='inner', on='SK_ID_PREV')\n",
    "del(cash_counts)\n",
    "\n",
    "cash_by_prev_loan = previous[['SK_ID_CURR', 'SK_ID_PREV']].merge(cash_agg, how='left', on='SK_ID_PREV')\n",
    "cash_by_applicant = agg_numeric(cash_by_prev_loan, group_var='SK_ID_CURR', df_name = 'client_prev')\n",
    "del(cash_by_prev_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_counts = count_categorical(credit, group_var = 'SK_ID_PREV', df_name = 'credit')\n",
    "credit_agg = agg_numeric(credit, group_var = 'SK_ID_PREV', df_name = 'credit')\n",
    "credit_agg = credit_agg.merge(credit_counts, how='inner', on='SK_ID_PREV')\n",
    "del(credit_counts)\n",
    "\n",
    "credit_by_prev_loan = previous[['SK_ID_CURR', 'SK_ID_PREV']].merge(credit_agg, how='left', on='SK_ID_PREV')\n",
    "credit_by_applicant = agg_numeric(credit_by_prev_loan, group_var='SK_ID_CURR', df_name = 'client_credit')\n",
    "del(credit_by_prev_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installments_counts = count_categorical(installments, group_var = 'SK_ID_PREV', df_name = 'install')\n",
    "installments_agg = agg_numeric(installments, group_var = 'SK_ID_PREV', df_name = 'install')\n",
    "#installments_agg = installments_agg.merge(installments_counts, how='inner', on='SK_ID_PREV')\n",
    "#del(installments_counts)\n",
    "\n",
    "installments_by_prev_loan = previous[['SK_ID_CURR', 'SK_ID_PREV']].merge(installments_agg, how='left', on='SK_ID_PREV')\n",
    "installments_by_applicant = agg_numeric(installments_by_prev_loan, group_var='SK_ID_CURR', df_name = 'client_install')\n",
    "del(installments_by_prev_loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge with the value counts of previous\n",
    "app_train_df = app_train_df.merge(previous_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test_df = app_test_df.merge(previous_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of cash\n",
    "app_train_df = app_train_df.merge(cash_by_applicant, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test_df = app_test_df.merge(cash_by_applicant, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of credit\n",
    "app_train_df = app_train_df.merge(credit_by_applicant, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test_df = app_test_df.merge(credit_by_applicant, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Merge with the stats of installments\n",
    "app_train_df = app_train_df.merge(installments_by_applicant, on = 'SK_ID_CURR', how = 'left')\n",
    "app_test_df = app_test_df.merge(installments_by_applicant, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_df.to_csv(\"app_ALL_train.csv\", index=False)\n",
    "app_test_df.to_csv(\"app_ALL_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_mean_max</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_mean_mean</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_max_mean</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_max_max</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_max_min</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_min_mean</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_min_max</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_min_min</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_PAYMENT_CURRENT_mean_min</th>\n",
       "      <td>254658</td>\n",
       "      <td>82.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_ATM_CURRENT_mean_mean</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_max_max</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_max_mean</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_mean_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_mean_max</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_mean_mean</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_ATM_CURRENT_min_max</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_max_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_ATM_CURRENT_min_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_min_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_min_max</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_min_mean</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_max_max</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_max_mean</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_mean_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_max_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_POS_CURRENT_mean_mean</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_min_max</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_min_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_ATM_CURRENT_max_mean</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_ATM_CURRENT_mean_min</th>\n",
       "      <td>254570</td>\n",
       "      <td>82.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_INCOME_PERCENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCOME_CREDIT_PERC</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1349 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Total      %\n",
       "client_credit_credit_AMT_PAYMENT_CURRENT_mean_max   254658  82.82\n",
       "client_credit_credit_AMT_PAYMENT_CURRENT_mean_mean  254658  82.82\n",
       "client_credit_credit_AMT_PAYMENT_CURRENT_max_mean   254658  82.82\n",
       "client_credit_credit_AMT_PAYMENT_CURRENT_max_max    254658  82.82\n",
       "client_credit_credit_AMT_PAYMENT_CURRENT_max_min    254658  82.82\n",
       "...                                                    ...    ...\n",
       "REG_CITY_NOT_WORK_CITY                                   0   0.00\n",
       "REG_CITY_NOT_LIVE_CITY                                   0   0.00\n",
       "LIVE_REGION_NOT_WORK_REGION                              0   0.00\n",
       "REG_REGION_NOT_WORK_REGION                               0   0.00\n",
       "SK_ID_CURR                                               0   0.00\n",
       "\n",
       "[1349 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train_missing_df = pd.DataFrame(app_train_df.isna().sum(axis=0).sort_values(ascending=False)).rename(columns={0:\"Total\"})\n",
    "app_train_missing_df['%'] = np.round(app_train_missing_df.Total/len(app_train_df)*100, 2)\n",
    "app_train_missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_mean_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_mean_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_POS_CURRENT_max_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_POS_CURRENT_mean_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_POS_CURRENT_mean_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_POS_CURRENT_mean_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_min_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_min_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_min_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_min_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_min_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_min_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_max_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_max_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_max_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_max_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_max_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_mean_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_mean_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_mean_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT_max_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_POS_CURRENT_max_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_POS_CURRENT_max_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_CNT_DRAWINGS_POS_CURRENT_min_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_OTHER_CURRENT_min_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_POS_CURRENT_min_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_POS_CURRENT_min_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_POS_CURRENT_max_min</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_POS_CURRENT_max_max</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_credit_credit_AMT_DRAWINGS_POS_CURRENT_max_mean</th>\n",
       "      <td>39650</td>\n",
       "      <td>81.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_INCOME_PERCENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCOME_CREDIT_PERC</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1349 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Total      %\n",
       "client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT...  39650  81.34\n",
       "client_credit_credit_CNT_DRAWINGS_OTHER_CURRENT...  39650  81.34\n",
       "client_credit_credit_CNT_DRAWINGS_POS_CURRENT_m...  39650  81.34\n",
       "client_credit_credit_CNT_DRAWINGS_POS_CURRENT_m...  39650  81.34\n",
       "client_credit_credit_CNT_DRAWINGS_POS_CURRENT_m...  39650  81.34\n",
       "...                                                   ...    ...\n",
       "INCOME_CREDIT_PERC                                      0   0.00\n",
       "REG_CITY_NOT_WORK_CITY                                  0   0.00\n",
       "REG_CITY_NOT_LIVE_CITY                                  0   0.00\n",
       "LIVE_REGION_NOT_WORK_REGION                             0   0.00\n",
       "SK_ID_CURR                                              0   0.00\n",
       "\n",
       "[1349 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_test_missing_df = pd.DataFrame(app_test_df.isna().sum(axis=0).sort_values(ascending=False)).rename(columns={0:\"Total\"})\n",
    "app_test_missing_df['%'] = np.round(app_test_missing_df.Total/len(app_test_df)*100, 2)\n",
    "app_test_missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307500, 1349)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.784034\tvalid's binary_logloss: 0.531399\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid's auc: 0.784501\tvalid's binary_logloss: 0.517955\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.787252\tvalid's binary_logloss: 0.53047\n",
      "[400]\tvalid's auc: 0.788228\tvalid's binary_logloss: 0.502093\n",
      "Early stopping, best iteration is:\n",
      "[316]\tvalid's auc: 0.788857\tvalid's binary_logloss: 0.512807\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.780066\tvalid's binary_logloss: 0.528339\n",
      "[400]\tvalid's auc: 0.78166\tvalid's binary_logloss: 0.499476\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid's auc: 0.781833\tvalid's binary_logloss: 0.496596\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.785341\tvalid's binary_logloss: 0.52729\n",
      "[400]\tvalid's auc: 0.786862\tvalid's binary_logloss: 0.498157\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid's auc: 0.78706\tvalid's binary_logloss: 0.507447\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid's auc: 0.786669\tvalid's binary_logloss: 0.53526\n",
      "[400]\tvalid's auc: 0.787679\tvalid's binary_logloss: 0.507176\n",
      "Early stopping, best iteration is:\n",
      "[394]\tvalid's auc: 0.787778\tvalid's binary_logloss: 0.507827\n"
     ]
    }
   ],
   "source": [
    "train = app_train_df.iloc[:,1:].copy()\n",
    "test = app_test_df.iloc[:,1:].copy()\n",
    "label = train_label['TARGET'].copy()\n",
    "\n",
    "cv_n_estimators = []\n",
    "cv_scores = []\n",
    "fi = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, val_index in skf.split(X=train, y=label):\n",
    "    #X_train, y_train = train[train_index], label[train_index]\n",
    "    #X_val, y_val = train[val_index], label[val_index]\n",
    "    \n",
    "    # Split as DataFrame\n",
    "    X_train, y_train = train.iloc[train_index,:], label.iloc[train_index]\n",
    "    X_val, y_val = train.iloc[val_index,:], label.iloc[val_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = LGBMClassifier(device='GPU',\n",
    "                           silent=False,\n",
    "                           n_estimators=10000, \n",
    "                           num_leaves=31,\n",
    "                           objective = 'binary', \n",
    "                           class_weight = 'balanced', \n",
    "                           learning_rate = 0.05, \n",
    "                           #reg_alpha = 0.1, \n",
    "                           #reg_lambda = 0.1, \n",
    "                           subsample = 0.8, \n",
    "                           colsample_by_tree=0.50,\n",
    "                           n_jobs = 4, \n",
    "                           random_state = 2)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              eval_metric = 'auc',\n",
    "              eval_set = [(X_val, y_val)],\n",
    "              eval_names = ['valid'], \n",
    "              categorical_feature = 'auto',\n",
    "              early_stopping_rounds = 100, \n",
    "              verbose = 200)\n",
    "    \n",
    "    cv_n_estimators.append(model.best_iteration_)\n",
    "    cv_scores.append(model.best_score_['valid']['auc'])\n",
    "    fi.append(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_estimators: [287, 316, 424, 327, 394]\n",
      "Best n_estimators (AVG): 349.6\n",
      "Best CV AUCs: [0.7845012690360755, 0.788857323893546, 0.7818329259980382, 0.7870599081940427, 0.7877778250507216]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best n_estimators: {}\".format(cv_n_estimators))\n",
    "print(\"Best n_estimators (AVG): {}\".format(np.mean(cv_n_estimators)))\n",
    "print(\"Best CV AUCs: {}\".format(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>FI</th>\n",
       "      <th>FI_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ORGANIZATION_TYPE</td>\n",
       "      <td>6223</td>\n",
       "      <td>0.118669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>CREDIT_TERM</td>\n",
       "      <td>1453</td>\n",
       "      <td>0.027708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3</td>\n",
       "      <td>776</td>\n",
       "      <td>0.014798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMT_ANNUITY</td>\n",
       "      <td>695</td>\n",
       "      <td>0.013253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OCCUPATION_TYPE</td>\n",
       "      <td>659</td>\n",
       "      <td>0.012567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EXT_SOURCE_1_x</td>\n",
       "      <td>622</td>\n",
       "      <td>0.011861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>bureau_DAYS_CREDIT_max</td>\n",
       "      <td>521</td>\n",
       "      <td>0.009935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMT_CREDIT</td>\n",
       "      <td>436</td>\n",
       "      <td>0.008314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OWN_CAR_AGE</td>\n",
       "      <td>420</td>\n",
       "      <td>0.008009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>bureau_DAYS_CREDIT_ENDDATE_max</td>\n",
       "      <td>418</td>\n",
       "      <td>0.007971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DAYS_ID_PUBLISH</td>\n",
       "      <td>410</td>\n",
       "      <td>0.007818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>client_prev_cash_CNT_INSTALMENT_FUTURE_mean_mean</td>\n",
       "      <td>409</td>\n",
       "      <td>0.007799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>DAYS_EMPLOYED_PERCENT</td>\n",
       "      <td>406</td>\n",
       "      <td>0.007742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMT_GOODS_PRICE</td>\n",
       "      <td>404</td>\n",
       "      <td>0.007704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>client_install_install_AMT_PAYMENT_min_sum</td>\n",
       "      <td>402</td>\n",
       "      <td>0.007666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>bureau_AMT_CREDIT_SUM_DEBT_mean</td>\n",
       "      <td>361</td>\n",
       "      <td>0.006884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>client_install_install_AMT_PAYMENT_min_min</td>\n",
       "      <td>343</td>\n",
       "      <td>0.006541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>bureau_DAYS_ENDDATE_FACT_max</td>\n",
       "      <td>340</td>\n",
       "      <td>0.006484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>client_install_install_AMT_PAYMENT_min_mean</td>\n",
       "      <td>333</td>\n",
       "      <td>0.006350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>330</td>\n",
       "      <td>0.006293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ANNUITY_INCOME_PERCENT</td>\n",
       "      <td>328</td>\n",
       "      <td>0.006255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>previous_NAME_CONTRACT_STATUS_Refused_count_norm</td>\n",
       "      <td>315</td>\n",
       "      <td>0.006007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>EXT_SOURCE_2 EXT_SOURCE_3^2</td>\n",
       "      <td>302</td>\n",
       "      <td>0.005759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DAYS_EMPLOYED</td>\n",
       "      <td>285</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>DAYS_LAST_PHONE_CHANGE</td>\n",
       "      <td>280</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>EXT_SOURCE_3_x</td>\n",
       "      <td>278</td>\n",
       "      <td>0.005301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>client_prev_cash_CNT_INSTALMENT_FUTURE_mean_max</td>\n",
       "      <td>277</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH</td>\n",
       "      <td>274</td>\n",
       "      <td>0.005225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DAYS_REGISTRATION</td>\n",
       "      <td>271</td>\n",
       "      <td>0.005168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>previous_CNT_PAYMENT_mean</td>\n",
       "      <td>255</td>\n",
       "      <td>0.004863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_OTHER_CURREN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_OTHER_CURREN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_OTHER_CURREN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_OTHER_CURREN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_OTHER_CURREN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_OTHER_CURREN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_OTHER_CURREN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>client_credit_credit_AMT_BALANCE_mean_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>client_credit_credit_AMT_BALANCE_max_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>client_credit_credit_AMT_BALANCE_min_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>client_credit_credit_AMT_BALANCE_sum_count</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>client_credit_credit_AMT_CREDIT_LIMIT_ACTUAL_s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>client_prev_cash_NAME_CONTRACT_STATUS_Amortize...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1594 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature    FI  FI_normalized\n",
       "34                                   ORGANIZATION_TYPE  6223       0.118669\n",
       "130                                        CREDIT_TERM  1453       0.027708\n",
       "118             EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3   776       0.014798\n",
       "7                                          AMT_ANNUITY   695       0.013253\n",
       "23                                     OCCUPATION_TYPE   659       0.012567\n",
       "..                                                 ...   ...            ...\n",
       "952  client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...     0       0.000000\n",
       "953  client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...     0       0.000000\n",
       "954  client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...     0       0.000000\n",
       "959  client_credit_credit_AMT_DRAWINGS_ATM_CURRENT_...     0       0.000000\n",
       "797  client_prev_cash_NAME_CONTRACT_STATUS_Amortize...     0       0.000000\n",
       "\n",
       "[1594 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_arr = np.zeros_like(fi[0])\n",
    "for fi_cv in fi:\n",
    "    fi_arr += fi_cv\n",
    "\n",
    "fi_df = {}\n",
    "for name, fi_feat in zip(list(train.columns), fi_arr):\n",
    "    fi_df[name] = fi_feat\n",
    "fi_df = pd.DataFrame(pd.Series(fi_df), columns=['FI'])\n",
    "fi_df['FI_normalized'] = fi_df['FI'] / fi_df['FI'].sum()\n",
    "fi_df.reset_index(level=0, inplace=True)\n",
    "fi_df.rename(columns={'index':'Feature'}, inplace=True)\n",
    "fi_df.sort_values(by='FI', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_df.to_csv(\"fi_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_df = pd.read_csv(\"fi_3.csv\")\n",
    "low_fi_feats = list(fi_df[fi_df['FI']==0].Feature.values)\n",
    "\n",
    "train_drop_low_fi = train.copy()\n",
    "test_drop_low_fi = test.copy()\n",
    "\n",
    "train_drop_low_fi.drop(columns=low_fi_feats, inplace=True)\n",
    "test_drop_low_fi.drop(columns=low_fi_feats, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_label['TARGET'].copy()\n",
    "\n",
    "cv_n_estimators = []\n",
    "cv_scores = []\n",
    "fi = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for train_index, val_index in skf.split(X=train_drop_low_fi, y=label):\n",
    "    # Split as DataFrame\n",
    "    X_train, y_train = train_drop_low_fi.iloc[train_index,:], label.iloc[train_index]\n",
    "    X_val, y_val = train_drop_low_fi.iloc[val_index,:], label.iloc[val_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = LGBMClassifier(#device='GPU',\n",
    "                           #silent=False,\n",
    "                           n_estimators=10000, \n",
    "                           num_leaves=31,\n",
    "                           objective = 'binary', \n",
    "                           class_weight = 'balanced', \n",
    "                           learning_rate = 0.05, \n",
    "                           #reg_alpha = 0.1, \n",
    "                           #reg_lambda = 0.1, \n",
    "                           subsample = 0.8, \n",
    "                           colsample_by_tree=0.50,\n",
    "                           n_jobs = 6, \n",
    "                           random_state = 2)\n",
    "    \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              eval_metric = 'auc',\n",
    "              eval_set = [(X_val, y_val)],\n",
    "              eval_names = ['valid'], \n",
    "              categorical_feature = 'auto',\n",
    "              early_stopping_rounds = 100, \n",
    "              verbose = 200)\n",
    "    \n",
    "    cv_n_estimators.append(model.best_iteration_)\n",
    "    cv_scores.append(model.best_score_['valid']['auc'])\n",
    "    fi.append(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best n_estimators: {}\".format(cv_n_estimators))\n",
    "print(\"Best n_estimators (AVG): {}\".format(np.mean(cv_n_estimators)))\n",
    "print(\"Best CV AUCs: {}\".format(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi_arr = np.zeros_like(fi[0])\n",
    "for fi_cv in fi:\n",
    "    fi_arr += fi_cv\n",
    "\n",
    "fi_df = {}\n",
    "for name, fi_feat in zip(list(train_drop_low_fi.columns), fi_arr):\n",
    "    fi_df[name] = fi_feat\n",
    "fi_df = pd.DataFrame(pd.Series(fi_df), columns=['FI'])\n",
    "fi_df['FI_normalized'] = fi_df['FI'] / fi_df['FI'].sum()\n",
    "fi_df.sort_values(by='FI', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n",
       "               colsample_by_tree=0.5, colsample_bytree=1.0, device='GPU',\n",
       "               importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=380, n_jobs=4, num_leaves=31, objective='binary',\n",
       "               random_state=2, reg_alpha=0.0, reg_lambda=0.0, silent=False,\n",
       "               subsample=0.8, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMClassifier(device='GPU',\n",
    "                           silent=False,\n",
    "                           n_estimators=380, \n",
    "                           num_leaves=31,\n",
    "                           objective = 'binary', \n",
    "                           class_weight = 'balanced', \n",
    "                           learning_rate = 0.05, \n",
    "                           #reg_alpha = 0.1, \n",
    "                           #reg_lambda = 0.1, \n",
    "                           subsample = 0.8, \n",
    "                           colsample_by_tree=0.50,\n",
    "                           n_jobs = 4, \n",
    "                           random_state = 2)\n",
    "    \n",
    "model.fit(train_drop_low_fi, \n",
    "          label, \n",
    "          eval_metric = 'auc',\n",
    "          categorical_feature = 'auto',\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(test_drop_low_fi)[:,1]\n",
    "submission_df = pd.DataFrame(test_id)\n",
    "submission_df['TARGET'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"29082019_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **0.78023** - Poly, bureau, previous (cash) features\n",
    "- **0.77955** - Poly, bureau, previous (cash) features, FI<10\n",
    "- **0.78018** - Poly, bureau, previous (cash) features\n",
    "- **0.78025** - Poly, bureau, previous (cash) features, n_estimators=400\n",
    "- **0.77963** - Poly, bureau, previous (cash) features, n_estimators=500\n",
    "\n",
    "\n",
    "- **0.77904** - GPU training (colsample_by_tree doesn't work?) Different FI_2.csv.\n",
    "- **0.77930** - CPU training (colsample_by_tree?) Different FI_2.csv, Different seed\n",
    "\n",
    "\n",
    "- **0.78453** - ALL features, GPU training\n",
    "- **0.78416** - ALL features, CPU training\n",
    "- **0.78526** - ALL features, GPU training, 31 leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_drop_low_fi.to_csv(\"app_ALL_train_poly.csv\", index=False)\n",
    "test_drop_low_fi.to_csv(\"app_ALL_test_poly.csv\", index=False)\n",
    "#pd.DataFrame(label).to_csv(\"train_label_dropped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
